# Copyright 2025 Proyectos y Sistemas de Mantenimiento SL (eProsima).
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from enum import Enum

from vulcanai.console.logger import VulcanAILogger
from vulcanai.core.plan_types import AIValidation, GlobalPlan, GoalSpec


class Brand(str, Enum):
    gemini = "gemini"
    gpt = "gpt"
    ollama = "ollama"


class Agent:

    class_color = "#0d87c0"

    """Interface to operate the LLM."""
    def __init__(self, model_name: str, logger=None):
        self.brand, name = self._detect_brand(model_name)
        self.model = None
        self.logger = logger
        self._load_model(name)

    def inference_plan(
            self,
            system_context: str,
            user_prompt: str,
            images: list[str],
            history: list[tuple[str, str]]
        ) -> GlobalPlan:
        """
        Perform inference using the selected LLM model to generate a plan.

        :param system_context: The system prompt or context for the LLM.
        :param user_prompt: The user's input or request.
        :param images: List of image paths or URLs to include in the prompt.
        :param history: List of tuples containing previous user requests and plan summaries.
        :return: A GlobalPlan object generated by the LLM.
        """
        if self.model is None:
            raise RuntimeError("LLM model was not loaded correctly.")

        plan: GlobalPlan = self.model.plan_inference(
            system_prompt=system_context,
            user_prompt=user_prompt,
            images=images,
            history=history
        )

        return plan

    def inference_goal(
            self,
            system_context: str,
            user_prompt: str,
            history: list[tuple[str, str]]
        ) -> GoalSpec:
        """
        Perform inference using the selected LLM model to generate a goal.

        :param system_context: The system prompt or context for the LLM.
        :param user_prompt: The user's input or request.
        :param history: List of tuples containing previous user requests and plan summaries.
        :return: A GlobalPlan object generated by the LLM.
        """
        if self.model is None:
            raise RuntimeError("LLM model was not loaded correctly.")

        goal: GoalSpec = self.model.goal_inference(
            system_prompt=system_context,
            user_prompt=user_prompt,
            history=history
        )

        return goal

    def inference_validation(
            self,
            system_context: str,
            user_prompt: str,
            images: list[str],
            history: list[tuple[str, str]],
        ) -> AIValidation:
        """
        Perform inference using the selected LLM model to generate a validation.

        :param system_context: The system prompt or context for the LLM.
        :param user_prompt: The user's input or request.
        :param images: List of image paths or URLs to include in the prompt.
        :param history: List of tuples containing previous user requests and plan summaries.
        :return: An AIValidation object generated by the LLM.
        """
        if self.model is None:
            raise RuntimeError("LLM model was not loaded correctly.")

        validation: AIValidation = self.model.validation_inference(
            system_prompt=system_context,
            user_prompt=user_prompt,
            images=images,
            history=history
        )

        return validation

    def _detect_brand(self, model_name: str) -> tuple[Brand, str]:
        """
        Detect LLM brand from model name prefix.

        :param model_name: Full model name with brand prefix.
        :return: Tuple of (Brand enum, stripped model name).
        """
        m = model_name.lower()
        if m.startswith("ollama-"):
            return Brand.ollama, model_name[len("ollama-"):]
        if m.startswith(("gpt-", "o")):
            return Brand.gpt, model_name
        if m.startswith(("gemini-", "gemma-")):
            return Brand.gemini, model_name
        else:
            raise NotImplementedError(f"Model {model_name} not supported.")

    def _load_model(self, model_name: str):
        if self.brand == Brand.gpt:
            from vulcanai.models.openai import OpenAIModel
            # Print in textual terminal:
            # [MANAGER] Using OpenAI API with model: <model_name>
            self.logger.log_manager(f"Using OpenAI API with model: " + \
                        f"<{self.class_color}>{model_name}</{self.class_color}>")
            self.model = OpenAIModel(model_name, self.logger)

        elif self.brand == Brand.gemini:
            from vulcanai.models.gemini import GeminiModel
            # Print in textual terminal:
            # [MANAGER] Using Gemini API with model: <model_name>
            self.logger.log_manager(f"Using Gemini API with model: " + \
                        f"<{self.class_color}>{model_name}</{self.class_color}>")
            self.model = GeminiModel(model_name, self.logger)

        elif self.brand == Brand.ollama:
            from vulcanai.models.ollama_model import OllamaModel
            # Print in textual terminal:
            # [MANAGER] Using Ollama API with model: <model_name>
            self.logger.log_manager(f"Using Ollama API with model: " + \
                        f"<{self.class_color}>{model_name}</{self.class_color}>")
            self.model = OllamaModel(model_name, self.logger)

        else:
            raise NotImplementedError(f"LLM brand {self.brand} not supported.")

    def set_hooks(self, hooks) -> None:
        """Set hooks for LLM activity."""
        if self.model:
            try:
                self.model.hooks = hooks
                # Print in textual terminal:
                # [MANAGER] LLM hooks set.
                # TODO. danip
                #self.logger("LLM hooks set.",
                #            log_type="manager")
                self.logger.log_manager("LLM hooks set.")
            except Exception as e:
                # Print in textual terminal:
                # [MANAGER] ERROR. Failed to set LLM hooks: <exception>
                # TODO. danip
                #self.logger(f"ERROR. Failed to set LLM hooks: {e}",
                #            log_type="manager", log_color=0)
                self.logger.log_manager(f"Failed to set LLM hooks: {e}", error=True)
        else:
            # Print in textual terminal:
            # [MANAGER] ERROR. LLM model not initialized, cannot set hooks.
            # TODO. danip
            #self.logger("ERROR. LLM model not initialized, cannot set hooks.",
            #            log_type="manager", log_color=0)
            self.logger.log_manager("LLM model not initialized, cannot set hooks.", error=True)
